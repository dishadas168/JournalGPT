{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pypandoc\n",
        "!pip install -qU \\\n",
        "    datasets==2.14.4 \\\n",
        "    langchain==0.0.274 \\\n",
        "    pinecone-client==2.2.2 \\\n",
        "    openai==0.27.9\n",
        "!pip install pyrate-limiter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v139W7n41Nzn",
        "outputId": "aeccef8e-2986-4516-b205-f1af60688bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (1.11)\n",
            "Collecting pyrate-limiter\n",
            "  Downloading pyrate_limiter-3.1.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyrate-limiter\n",
            "Successfully installed pyrate-limiter-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "import re\n",
        "from pyrate_limiter import Duration, Limiter, Rate\n",
        "import time\n",
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "riRPEiuMAvKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.organization = \"\"\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "xdfi5mCpCcCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT JOURNAL"
      ],
      "metadata": {
        "id": "dr2gPUyPA2Pm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6kVpmLy02-r"
      },
      "outputs": [],
      "source": [
        "docxFilename = '2015.docx'\n",
        "output = pypandoc.convert_file(docxFilename, 'plain', outputfile=\"2015.txt\")\n",
        "assert output == \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE THE DATA"
      ],
      "metadata": {
        "id": "tgOJDZzPF5MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "journal = open(\"2015.txt\",\"r\")\n",
        "journal_txt = journal.read()"
      ],
      "metadata": {
        "id": "KfvAR2hIF9D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = ['\\n','|','--','+','=']\n",
        "for s in splits:\n",
        "  journal_txt = journal_txt.replace(s, \"\")\n",
        "journal_txt = journal_txt.replace(\"  \", \" \")\n",
        "journal_list= journal_txt.split(\" \")"
      ],
      "metadata": {
        "id": "U3g_zoxKaBoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def raw_text_to_entries(journal_list):\n",
        "\n",
        "  months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "  dates = ['(st)', '(nd)', '(rd)', '(th)']\n",
        "  month_index = {months[i]: i+1 for i in range(len(months)) }\n",
        "  year=2015\n",
        "\n",
        "  month=0\n",
        "  date=0\n",
        "  day=\"\"\n",
        "  date_new=\"0-0-0\"\n",
        "  location=\"\"\n",
        "  entries = []\n",
        "  entry = []\n",
        "\n",
        "  for i in range(len(journal_list)):\n",
        "\n",
        "      if journal_list[i] in months:\n",
        "        if journal_list[i-1][-4:] in dates:\n",
        "\n",
        "          entries.append({\n",
        "              'date' : date_new,\n",
        "              'location' : location,\n",
        "              'entry' : \" \".join(entry[:-3])\n",
        "          })\n",
        "          entry=[]\n",
        "\n",
        "          month = journal_list[i]\n",
        "          date = journal_list[i-1][:-5]\n",
        "          day = journal_list[i-2][:-1]\n",
        "          l = 3\n",
        "          while not len(journal_list[i-l])>0:\n",
        "            l+=1\n",
        "          location = journal_list[i-l]\n",
        "          date_new = f\"{month_index[month]:02}-{int(date):02}-{year}\"\n",
        "      else:\n",
        "        entry.append(journal_list[i])\n",
        "\n",
        "  for l in range(i,len(journal_list)):\n",
        "    entry.append(journal_list[l])\n",
        "\n",
        "  entries.append({\n",
        "      'date' : date_new,\n",
        "      'location' : location,\n",
        "      'entry' : \" \".join(entry)\n",
        "  })\n",
        "  entries = entries[1:]\n",
        "  return entries"
      ],
      "metadata": {
        "id": "sBHZO_zsIubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(entries)"
      ],
      "metadata": {
        "id": "SBV3XWt-myzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATE PROMPTS"
      ],
      "metadata": {
        "id": "oIuGDO_m-dz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_text(query_text, common_args):\n",
        "\n",
        "    try:\n",
        "\n",
        "        response = (\n",
        "          openai.Completion.create(\n",
        "              **common_args,\n",
        "              prompt=query_text,\n",
        "          )\n",
        "        )\n",
        "        answer = response['choices'][0]['text'].strip()\n",
        "        # print(response)\n",
        "        return answer\n",
        "\n",
        "    except Exception as exc:\n",
        "        print(\"Error completing text: %s\", exc)\n"
      ],
      "metadata": {
        "id": "kG-y8kV-1ILB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_args = {\n",
        "    \"model\": \"text-davinci-003\",\n",
        "    \"max_tokens\": 2500,\n",
        "}\n",
        "results = []\n",
        "\n",
        "for entry in entries:\n",
        "  query_text = f\"\"\"\n",
        "  I am the narrator of the given text. You are a compassionate psychologist who wants to get to know me by asking\n",
        "  insightful, thought-provoking, meaningful questions about my day.\n",
        "  Generate atleast 3 interesting thought-provoking question-answer pairs from the given text.\n",
        "  Use the following pattern:\n",
        "  'Question': How did you feel when you thought something might have happened to your father?\n",
        "  'Answer': When I saw my father's leg immersed into the drain, I felt a wave of fear wash over me.\n",
        "  I feared the worst and I thought he might be injured or worse, and I couldn't help but feel a sense of helplessness.\n",
        "  Thankfully, nothing bad happened and I was relieved.\n",
        "\n",
        "  Date: {entry['date']}\n",
        "  Location: {entry['location']}\n",
        "  Journal entry: {entry['entry']}\n",
        "  \"\"\"\n",
        "  answer = complete_text(entry, common_args)\n",
        "  time.sleep(15)\n",
        "  text_file = open(\"data_01.txt\", \"a\")\n",
        "  text_file.write(answer)\n",
        "  text_file.close()\n",
        "  results.append(answer)\n"
      ],
      "metadata": {
        "id": "4YDUURDP-hEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28i3DIg_v2dO",
        "outputId": "224a2d66-e195-4992-f0ca-effb45dfa62a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Prompt: What motivated you to make this New Year's day perfect?\\n  Completion: I was motivated to make this New Year's Day perfect because it was a special day, and I wanted to make the most of it. I wanted to start off the new year in the right way and create lasting memories with my family and friends.\",\n",
              " \"Prompt: How did you react when you saw your father's leg immersed into the drain?\\n  Answer: When I saw my father's leg immersed into the drain, I felt shock and a wave of fear wash over me. I quickly ran to him to check if he was okay and my mind raced to think of the worst possible outcome. Thankfully nothing bad happened and I was immensely relieved.\",\n",
              " 'Prompt: What did you feel when you got the auto to the cinema?\\nCompletion: When I saw the auto arrive, I felt a sense of relief wash over me. I was so sure that it would arrive and my faith was rewarded. I was excited for the movie and happy to be out with my friends on an adventure.']"
            ]
          },
          "metadata": {},
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERT PROMPT TEXT FILE TO JSONL FILE"
      ],
      "metadata": {
        "id": "X56zcH9lC7D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TBD"
      ],
      "metadata": {
        "id": "qqcrqUZ0DAXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE FOR FINE-TUNING JOB"
      ],
      "metadata": {
        "id": "kI78bCs7DC9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = openai.File.create(\n",
        "    file=open(\"conversations.jsonl\", \"r\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "res"
      ],
      "metadata": {
        "id": "i7oMVblx107D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = res[\"id\"]\n",
        "file_id"
      ],
      "metadata": {
        "id": "ZB1Tpk1P3UWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = openai.FineTuningJob.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
        "res"
      ],
      "metadata": {
        "id": "J72tbPfN3Wxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = res[\"id\"]\n",
        "job_id"
      ],
      "metadata": {
        "id": "Qe46daqV3ZLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.retrieve(job_id)"
      ],
      "metadata": {
        "id": "XYEHTnF-3b6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list_events(id=job_id)"
      ],
      "metadata": {
        "id": "1LKdF1YT3eRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "while True:\n",
        "    res = openai.FineTuningJob.retrieve(job_id)\n",
        "    if res[\"finished_at\"] != None:\n",
        "        break\n",
        "    else:\n",
        "        print(\".\", end=\"\")\n",
        "        sleep(100)"
      ],
      "metadata": {
        "id": "dDRNsHqQ3hOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "2o7jDDBi3pYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = res[\"fine_tuned_model\"]\n",
        "ft_model"
      ],
      "metadata": {
        "id": "KvXdSp4e3rUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = 'ft:gpt-3.5-turbo-0613:pinecone::7s8gnk9R'"
      ],
      "metadata": {
        "id": "uvhmZ0a13twR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEED JOURNAL DATA TO PINECONE"
      ],
      "metadata": {
        "id": "yww5QAp2DiwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "res = requests.get('https://raw.githubusercontent.com/pinecone-io/examples/master/learn/generation/openai/fine-tuning/gpt-3.5-agent-training/chains.py')\n",
        "with open(\"chains.py\", 'w') as fp:\n",
        "    fp.write(res.text)"
      ],
      "metadata": {
        "id": "mD_LM5AP3v9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZE LANGCHAIN AGENT FOR CHAT SESSION"
      ],
      "metadata": {
        "id": "NqEdNtW3DrM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from chains import VectorDBChain\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.5,\n",
        "    model_name=ft_model\n",
        ")\n",
        "\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    k=5,\n",
        "    return_messages=True,\n",
        "    output_key=\"output\"\n",
        ")\n",
        "# app.pinecone.io\n",
        "vdb = VectorDBChain(\n",
        "    index_name=\"llama-2-arxiv-papers\",\n",
        "    environment=os.getenv(\"PINECONE_ENV\") or \"YOUR_ENV\",\n",
        "    pinecone_api_key=os.getenv(\"PINECONE_API_KEY\") or \"YOUR_KEY\"\n",
        ")\n",
        "\n",
        "vdb_tool = Tool(\n",
        "    name=vdb.name,\n",
        "    func=vdb.query,\n",
        "    description=\"This tool allows you to get research information about LLMs.\"\n",
        ")"
      ],
      "metadata": {
        "id": "lgRPUWJX3zVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=[vdb_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method=\"generate\",\n",
        "    memory=memory,\n",
        "    return_intermediate_steps=True\n",
        ")"
      ],
      "metadata": {
        "id": "_pbbaSZ731pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent(\"tell me about Llama 2?\")"
      ],
      "metadata": {
        "id": "zOh46FDg34AA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}