{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pypandoc\n",
        "!pip install -qU \\\n",
        "    datasets==2.14.4 \\\n",
        "    langchain==0.0.274 \\\n",
        "    pinecone-client==2.2.2 \\\n",
        "    openai==0.27.9\n",
        "!pip install pyrate-limiter\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v139W7n41Nzn",
        "outputId": "49490bde-9b27-453f-f09a-bbe619bb46d4"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (1.11)\n",
            "Requirement already satisfied: pyrate-limiter in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pypandoc\n",
        "import re\n",
        "from pyrate_limiter import Duration, Limiter, Rate\n",
        "import time\n",
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "riRPEiuMAvKX"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.organization = \"\"\n",
        "openai.api_key = \"\"\n",
        "\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "xdfi5mCpCcCT"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE THE DATA"
      ],
      "metadata": {
        "id": "tgOJDZzPF5MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "journal = open(\"2015.txt\",\"r\")\n",
        "journal_txt = journal.read()"
      ],
      "metadata": {
        "id": "KfvAR2hIF9D-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = ['\\n','|','--','+','=']\n",
        "for s in splits:\n",
        "  journal_txt = journal_txt.replace(s, \"\")\n",
        "journal_txt = journal_txt.replace(\"  \", \" \")\n",
        "journal_list= journal_txt.split(\" \")"
      ],
      "metadata": {
        "id": "U3g_zoxKaBoc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def raw_text_to_entries(journal_list):\n",
        "\n",
        "  months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
        "  dates = ['(st)', '(nd)', '(rd)', '(th)']\n",
        "  month_index = {months[i]: i+1 for i in range(len(months)) }\n",
        "  year=2015\n",
        "\n",
        "  month=0\n",
        "  date=0\n",
        "  day=\"\"\n",
        "  date_new=\"0-0-0\"\n",
        "  location=\"\"\n",
        "  entries = []\n",
        "  entry = []\n",
        "\n",
        "  for i in range(len(journal_list)):\n",
        "\n",
        "      if journal_list[i] in months:\n",
        "        if journal_list[i-1][-4:] in dates:\n",
        "\n",
        "          entries.append({\n",
        "              'date' : date_new,\n",
        "              'location' : location,\n",
        "              'entry' : \" \".join(entry[:-3])\n",
        "          })\n",
        "          entry=[]\n",
        "\n",
        "          month = journal_list[i]\n",
        "          date = journal_list[i-1][:-5]\n",
        "          day = journal_list[i-2][:-1]\n",
        "          l = 3\n",
        "          while not len(journal_list[i-l])>0:\n",
        "            l+=1\n",
        "          location = journal_list[i-l]\n",
        "          date_new = f\"{month_index[month]:02}-{int(date):02}-{year}\"\n",
        "      else:\n",
        "        entry.append(journal_list[i])\n",
        "\n",
        "  for l in range(i,len(journal_list)):\n",
        "    entry.append(journal_list[l])\n",
        "\n",
        "  entries.append({\n",
        "      'date' : date_new,\n",
        "      'location' : location,\n",
        "      'entry' : \" \".join(entry)\n",
        "  })\n",
        "  entries = entries[1:]\n",
        "  return entries"
      ],
      "metadata": {
        "id": "sBHZO_zsIubn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entries = raw_text_to_entries(journal_list)\n",
        "entries[279][\"date\"]"
      ],
      "metadata": {
        "id": "SBV3XWt-myzK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "247c671c-9f91-41b8-f30c-890856c47b90"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10-07-2015'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATE PROMPTS"
      ],
      "metadata": {
        "id": "oIuGDO_m-dz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "p7RtbijJCfEG"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_schemas = [\n",
        "    ResponseSchema(name=\"prompt\", description=\"question from the question-answer pair\"),\n",
        "    ResponseSchema(name=\"completion\", description=\"answer from the question-answer pair\")\n",
        "]"
      ],
      "metadata": {
        "id": "n6qOxOD2DY-s"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "print(output_parser)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ga99cZiD-HL",
        "outputId": "53d89561-c7bc-41d8-8183-2cd51e81f075"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response_schemas=[ResponseSchema(name='prompt', description='question from the question-answer pair', type='string'), ResponseSchema(name='completion', description='answer from the question-answer pair', type='string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He3bma7wEJ65",
        "outputId": "1a17b760-4d2e-4b56-9286-10e11b6454cf"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"prompt\": string  // question from the question-answer pair\n",
            "\t\"completion\": string  // answer from the question-answer pair\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template1 = \"\"\"\n",
        "  I am the narrator of the given text. You are a compassionate psychologist who wants to get to know me by asking\n",
        "  insightful, thought-provoking, meaningful questions about my day.\n",
        "  Generate atleast 3 interesting thought-provoking question-answer pairs from the given text.\n",
        "  The answers should be expressive with as many details as possible. Strictly follow the output formatting given below\\n\n",
        "  Date: {entry_date}\\n\n",
        "  Location: {entry_location}\\n\n",
        "  Journal entry: {entry_text}\\n\\n\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ZWl_L4TVF2J_"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template1 + \"\\n{format_instructions}\",\n",
        "    input_variables=[\"entry_date\", \"entry_location\", \"entry_text\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ],
      "metadata": {
        "id": "arTfiRuCEYdb"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.1, model=\"text-davinci-003\", max_tokens=1024)"
      ],
      "metadata": {
        "id": "y6VmSzW1Hb-B"
      },
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for entry in entries:\n",
        "  prompt_ = prompt.format(\n",
        "      entry_date = entry[\"date\"],\n",
        "      entry_location = entry['location'],\n",
        "      entry_text = entry[\"entry\"]\n",
        "  )\n",
        "  outputs = llm(prompt_)\n",
        "  outputs = outputs.split(\"\\n\\n\")[1:]\n",
        "  while len(output) > 0 and not output[0].startswith(\"```json\"):\n",
        "    output = output[1:]\n",
        "\n",
        "  print(outputs)\n",
        "  for output in outputs[1:]:\n",
        "    out = output_parser.parse(output)\n",
        "    results.append(out)\n",
        "    # print(results)\n",
        "  print(entry['date'])\n",
        "\n"
      ],
      "metadata": {
        "id": "4YDUURDP-hEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyQPceXac5qw",
        "outputId": "8fa6ee91-38b7-4765-f0e8-5b40062e92f4"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "849"
            ]
          },
          "metadata": {},
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERT PROMPT TEXT FILE TO JSONL FILE"
      ],
      "metadata": {
        "id": "X56zcH9lC7D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"data.jsonl\", 'a') as f:\n",
        "    for item in results:\n",
        "        f.write(json.dumps(item) + \"\\n\")"
      ],
      "metadata": {
        "id": "IAP8YRJ0cOVn"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE FOR FINE-TUNING JOB"
      ],
      "metadata": {
        "id": "kI78bCs7DC9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = openai.File.create(\n",
        "    file=open(\"data.jsonl\", \"r\"),\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "res"
      ],
      "metadata": {
        "id": "i7oMVblx107D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f21c04-d89d-4df5-c02f-c04ec75122dd"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<File file id=file-FRR5gOUo1kMTOrGpX5GmU7Ge at 0x79c1f5020e50> JSON: {\n",
              "  \"object\": \"file\",\n",
              "  \"id\": \"file-FRR5gOUo1kMTOrGpX5GmU7Ge\",\n",
              "  \"purpose\": \"fine-tune\",\n",
              "  \"filename\": \"file\",\n",
              "  \"bytes\": 225670,\n",
              "  \"created_at\": 1693993204,\n",
              "  \"status\": \"uploaded\",\n",
              "  \"status_details\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = res[\"id\"]\n",
        "file_id"
      ],
      "metadata": {
        "id": "ZB1Tpk1P3UWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e0cd0df0-9ee8-404b-d83a-fe0d9224da3f"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-FRR5gOUo1kMTOrGpX5GmU7Ge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = openai.FineTuningJob.create(training_file=file_id, model=\"davinci-002\")\n",
        "res"
      ],
      "metadata": {
        "id": "J72tbPfN3Wxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8136f403-5c14-4746-8af0-f25cdc574f09"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-Lu3fVNuA16G8CUxaryAWQbuv at 0x79c1f5005530> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-Lu3fVNuA16G8CUxaryAWQbuv\",\n",
              "  \"model\": \"davinci-002\",\n",
              "  \"created_at\": 1693993609,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-NvHPb9ySxZah9npepkQbdNAd\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"created\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FRR5gOUo1kMTOrGpX5GmU7Ge\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = res[\"id\"]\n",
        "job_id"
      ],
      "metadata": {
        "id": "Qe46daqV3ZLx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ef6832db-a0be-4878-93d1-afc9fe0c245f"
      },
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-Lu3fVNuA16G8CUxaryAWQbuv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.retrieve(job_id)"
      ],
      "metadata": {
        "id": "XYEHTnF-3b6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4c7b2d-4f06-46f8-e64b-d425a27df6b4"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-Lu3fVNuA16G8CUxaryAWQbuv at 0x79c1f4e9a2a0> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-Lu3fVNuA16G8CUxaryAWQbuv\",\n",
              "  \"model\": \"davinci-002\",\n",
              "  \"created_at\": 1693993609,\n",
              "  \"finished_at\": null,\n",
              "  \"fine_tuned_model\": null,\n",
              "  \"organization_id\": \"org-NvHPb9ySxZah9npepkQbdNAd\",\n",
              "  \"result_files\": [],\n",
              "  \"status\": \"running\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FRR5gOUo1kMTOrGpX5GmU7Ge\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.FineTuningJob.list_events(id=job_id)"
      ],
      "metadata": {
        "id": "1LKdF1YT3eRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeeb06db-1ae9-4db6-b18c-13bbab6f5429"
      },
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x79c1f4e98ae0> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-h0g5VQk3hthNH5kGz51rNtM5\",\n",
              "      \"created_at\": 1693993614,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Fine tuning job started\",\n",
              "      \"data\": null,\n",
              "      \"type\": \"message\"\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job.event\",\n",
              "      \"id\": \"ftevent-HwgZt89CHrwKyJCfePq1qHxw\",\n",
              "      \"created_at\": 1693993609,\n",
              "      \"level\": \"info\",\n",
              "      \"message\": \"Created fine-tune: ftjob-Lu3fVNuA16G8CUxaryAWQbuv\",\n",
              "      \"data\": null,\n",
              "      \"type\": \"message\"\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 375
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "\n",
        "while True:\n",
        "    res = openai.FineTuningJob.retrieve(job_id)\n",
        "    if res[\"finished_at\"] != None:\n",
        "        break\n",
        "    else:\n",
        "        print(\".\", end=\"\")\n",
        "        sleep(100)"
      ],
      "metadata": {
        "id": "dDRNsHqQ3hOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e486794-2f35-44b4-f6ce-db3a00d574ca"
      },
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "2o7jDDBi3pYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7b8b3a-6e14-4142-87b1-4085631a9850"
      },
      "execution_count": 377,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-Lu3fVNuA16G8CUxaryAWQbuv at 0x79c1f50f32e0> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-Lu3fVNuA16G8CUxaryAWQbuv\",\n",
              "  \"model\": \"davinci-002\",\n",
              "  \"created_at\": 1693993609,\n",
              "  \"finished_at\": 1693994337,\n",
              "  \"fine_tuned_model\": \"ft:davinci-002:personal::7vjbGMEI\",\n",
              "  \"organization_id\": \"org-NvHPb9ySxZah9npepkQbdNAd\",\n",
              "  \"result_files\": [\n",
              "    \"file-GguTHpRmedLfirxNQVHhyNKK\"\n",
              "  ],\n",
              "  \"status\": \"succeeded\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-FRR5gOUo1kMTOrGpX5GmU7Ge\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": 141018\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 377
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = res[\"fine_tuned_model\"]\n",
        "ft_model"
      ],
      "metadata": {
        "id": "KvXdSp4e3rUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6c365dae-a5ea-43ae-8c5c-0ecffd798aba"
      },
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ft:davinci-002:personal::7vjbGMEI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 378
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = 'ft:davinci-002:personal::7vjbGMEI'"
      ],
      "metadata": {
        "id": "uvhmZ0a13twR"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEED JOURNAL DATA TO PINECONE"
      ],
      "metadata": {
        "id": "yww5QAp2DiwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "\n",
        "# res = requests.get('https://raw.githubusercontent.com/pinecone-io/examples/master/learn/generation/openai/fine-tuning/gpt-3.5-agent-training/chains.py')\n",
        "# with open(\"chains.py\", 'w') as fp:\n",
        "#     fp.write(res.text)"
      ],
      "metadata": {
        "id": "mD_LM5AP3v9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZE LANGCHAIN AGENT FOR CHAT SESSION"
      ],
      "metadata": {
        "id": "NqEdNtW3DrM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "# from chains import VectorDBChain\n",
        "\n",
        "llm = OpenAI(\n",
        "    temperature=0.0,\n",
        "    model_name=ft_model\n",
        ")\n",
        "\n",
        "# llm = ChatOpenAI(\n",
        "#     temperature=0.5,\n",
        "#     model_name=ft_model\n",
        "# )\n",
        "\n",
        "# memory = ConversationBufferWindowMemory(\n",
        "#     memory_key=\"chat_history\",\n",
        "#     k=5,\n",
        "#     return_messages=True,\n",
        "#     output_key=\"output\"\n",
        "# )\n",
        "# # app.pinecone.io\n",
        "# vdb = VectorDBChain(\n",
        "#     index_name=\"llama-2-arxiv-papers\",\n",
        "#     environment=os.getenv(\"PINECONE_ENV\") or \"YOUR_ENV\",\n",
        "#     pinecone_api_key=os.getenv(\"PINECONE_API_KEY\") or \"YOUR_KEY\"\n",
        "# )\n",
        "\n",
        "# vdb_tool = Tool(\n",
        "#     name=vdb.name,\n",
        "#     func=vdb.query,\n",
        "#     description=\"This tool allows you to get research information about LLMs.\"\n",
        "# )"
      ],
      "metadata": {
        "id": "lgRPUWJX3zVa"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm(\"What is the name of your roommate?\")"
      ],
      "metadata": {
        "id": "hyCDU7tmmG0F"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "eS5BJnDa8OBS",
        "outputId": "021de6d9-b973-4ac7-c71e-e5684924b1b9"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My roommate is Chetana. She is a very nice person and I am glad to have her as a roommate. We have a lot of fun together and I am looking forward to spending the next few days with her. She is also very supportive and understanding, which makes her a great roommate. I hope we can stay together for a long time. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already. I wish I could spend more time with her. I miss her already.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 421
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "C5pYbeP2niKu",
        "outputId": "b5f82acd-9a37-4302-ba4a-10331f58c88e"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I felt bad. I felt like I had let the team down. I felt like I had let myself down. I felt like I had let my family down. I felt like I had let my country down. I felt like I had let my coach down. I felt like I had let my fans down. I felt like I had let my teammates down. I felt like I had let my country down. I felt like I had let my coach down. I felt like I had let my fans down. I felt like I had let my teammates down. I felt like I had let my country down. I felt like I had let my coach down. I felt like I had let my fans down. I felt like I had let my teammates down. I felt like I had let my country down. I felt like I had let my coach down. I felt like I had let my fans down. I felt like I had let my teammates down. I felt like I had let my country down. I felt like I had let my coach down. I felt like I had let my fans down. I felt like I had let my teammates down. I felt like I had let my country down. I felt like I had let my coach down. I felt like'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.agents import AgentType, initialize_agent\n",
        "\n",
        "# agent = initialize_agent(\n",
        "#     agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "#     tools=[vdb_tool],\n",
        "#     llm=llm,\n",
        "#     verbose=True,\n",
        "#     max_iterations=3,\n",
        "#     early_stopping_method=\"generate\",\n",
        "#     memory=memory,\n",
        "#     return_intermediate_steps=True\n",
        "# )"
      ],
      "metadata": {
        "id": "_pbbaSZ731pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.Model.delete(ft_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSezuWtX3hXM",
        "outputId": "7fef4c09-928e-47bb-d20a-e20bb19db92f"
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Model model id=ft:davinci-002:personal::7vi4Ysy1 at 0x79c208949850> JSON: {\n",
              "  \"id\": \"ft:davinci-002:personal::7vi4Ysy1\",\n",
              "  \"object\": \"model\",\n",
              "  \"deleted\": true\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_dWpoBJ3r0k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}